## 全局锁

1. 概念:将整个库锁住,不能进行写和读操作
2. 命令:flush tables with read lock(FTWRL)
   - DML语句阻塞
   - DDL语句阻塞
   - 事物commit操作阻塞
3. 使用场景:
   - 全库逻辑备份,将每个表select查询出来后保存到文件中
   - 在主库上备份,此时实例则不能执行业务
   - 在备库上备份,binlog日志同步延时
4. 优化方案:一致性读,此时表需要支持事物的隔离级别
   - single-transaction:在导数据的时候开启一个事物,获取read-view快照,其他操作不影响该视图

## 表锁

1. 表锁
   - lock tables ... read/write,通过unlock table...来释放锁.读写不能并行
2. 元数据锁(用来隔离DDL和DML)
   - MDL(metadata lock),在访问一个表的时候自动加上
   - 作用:保证读写的正确性,当一个表被获取了MDL读锁后,不能获取MDL写锁
   - 进行DML操作获取MDL读锁,DDL操作获取MDL写锁
   - 对小表添加字段导致整个库宕机的行为分析
     - 比如session a,b 进行 DML查询操作;此时获取MDL读锁;session c进行 alter操作DDL操作需要获取MDL写锁,此时阻塞.后面的其他session获取MDL的读锁也会被session c阻塞,获取失败创建其他session导致整个数据库宕机
     - 解决长事物的问题,防止前面获取MDL读锁太长时间,导致后续操作阻塞session连接过多;可以通过观察information找到kill掉长事物后在进行DDL操作
     - 设定一定的等待时间去获取MDL的写锁,这个过程中如果有其他MDL读锁获取的操作则获取失败,然后进行重试
3. online(5.6 优化了表操作的DDL上的MDL情况)
   - 拿MDL写锁
   - 降级成MDL读锁
   - 真正DDL
   - 升级为MDL写锁
   - 释放MDL锁

### 问题

1. 当前数据库主备,备库在执行mysql dump的single-transaction备份从库中的数据,此时如果主库进行DDL语句结果是什么?

   - 备份库流程
   - 1.show create table
   - 2.保存表结构到文件中
   - 3.select * from 表,查询表中所有数据
   - 4.拼接insert语句
   - 5.写入到文件中
   - 6.提交事物
   - 注意事项:mvcc不增对DDL语句,当表结构修改后read-view视图会多一列

2. 分析流程:

   - 如果DDL的binlog日志在1之前到达,此时保存的表结构为最新数据,查询read-view字段最新,正常备份数据.主从数据保持一致

   - 如果ddl在2和3之间到达,此时保存的数据库表结构为旧,查询sql字段多一个字段,此时会报错.备份失败

   - 如果在3之后6之前到达,由于3进行DML查询后获取了MDL的读锁,此时DDL语句无法获取当前表的写锁阻塞,等待当前表备份完之后提交事物,MDL读锁释放,DDL可执行.现象:主库延迟

   - 如果在6之后,此时不会阻塞,跟第一种情况保持一致

     

## 行锁

1. 两阶段协议:当需要的时候获取锁,不需要的时候不是立刻释放,当事物结束后才释放当前行的锁
2. 死锁和死锁检测
   -  策略一:等待超时,通过show variables like "%Innodb_lock_wait_timeout%"来设置
   - 策略二:死锁检测,发现死锁当前事物放弃执行.show variables like "%Innodb_deadlock_detect%"
3. 如何解决并发下热点数据更新的问题?
   - 清楚自己的业务不会发生死锁,关闭死锁;当关闭死锁的时候,可能存在大量的请求超时业务不能接受
   - 控制并发度,比如控制当前更新操作的并发在10个,这样减少死锁的检测时间



### 问题

1. 删除一个表的前10000个数据,如下三种操作

   - ```sql
     delete from 表 limit 10000
     开启一个连接,进行20次delete from 表 limit 500
     开启20个连接,每次delete from 表 limit 500
     ```

2. 分析:

   - 第一种操作,整个事物过程;此时如果其中一条数据被更新获取了当前行的行锁,此时delete操作阻塞,主从延时
   - 第二个操作,正确答案.这样能降低每个事物的大小,删除其中一个数据段500,另外数据段被更新互不影响
   - 第三个操作,开启20个连接,人为造成锁冲突

